{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./desc.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBQuantile(XGBRegressor):\n",
    "    def __init__(self,\n",
    "        quant_alpha=0.95,\n",
    "        quant_delta = 1.0,\n",
    "        quant_thres=1.0,\n",
    "        quant_var =1.0,\n",
    "        base_score=0.5,\n",
    "        booster='gbtree',\n",
    "        colsample_bylevel=1,\n",
    "        colsample_bytree=1,\n",
    "        gamma=0, learning_rate=0.1, max_delta_step=0,max_depth=3,\n",
    "        min_child_weight=1, missing=None, n_estimators=100,\n",
    "        n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,silent=True, subsample=1\n",
    "    ):\n",
    "        self.quant_alpha = quant_alpha\n",
    "        self.quant_delta = quant_delta\n",
    "        self.quant_thres = quant_thres\n",
    "        self.quant_var = quant_var\n",
    "\n",
    "        super().__init__(base_score=base_score, booster=booster, colsample_bylevel=colsample_bylevel,\n",
    "            colsample_bytree=colsample_bytree, gamma=gamma, learning_rate=learning_rate, max_delta_step=max_delta_step,\n",
    "            max_depth=max_depth, min_child_weight=min_child_weight, missing=missing, n_estimators=n_estimators,\n",
    "            n_jobs= n_jobs, nthread=nthread, objective=objective, random_state=random_state,\n",
    "            reg_alpha=reg_alpha, reg_lambda=reg_lambda, scale_pos_weight=scale_pos_weight, seed=seed,\n",
    "            silent=silent, subsample=subsample)\n",
    "\n",
    "        self.test = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        super().set_params(objective=partial(XGBQuantile.quantile_loss,alpha = self.quant_alpha,delta = self.quant_delta,threshold = self.quant_thres,var = self.quant_var) )\n",
    "        super().fit(X,y)\n",
    "        return self\n",
    "  \n",
    "    def predict(self,X):\n",
    "        return super().predict(X)\n",
    "  \n",
    "    def score(self, X, y):\n",
    "        y_pred = super().predict(X)\n",
    "        score = XGBQuantile.quantile_score(y, y_pred, self.quant_alpha)\n",
    "        score = 1./score\n",
    "        return score\n",
    "      \n",
    "    @staticmethod\n",
    "    def quantile_loss(y_true,y_pred,alpha,delta,threshold,var):\n",
    "        x = y_true - y_pred\n",
    "        grad = (x<(alpha-1.0)*delta)*(1.0-alpha)-  ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )*x/delta-alpha*(x>alpha*delta)\n",
    "        hess = ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )/delta \n",
    "\n",
    "        grad = (np.abs(x)<threshold )*grad - (np.abs(x)>=threshold )*(2*np.random.randint(2, size=len(y_true)) -1.0)*var\n",
    "        hess = (np.abs(x)<threshold )*hess + (np.abs(x)>=threshold )\n",
    "        return grad, hess\n",
    "  \n",
    "    @staticmethod\n",
    "    def original_quantile_loss(y_true,y_pred,alpha,delta):\n",
    "        x = y_true - y_pred\n",
    "        grad = (x<(alpha-1.0)*delta)*(1.0-alpha)-((x>=(alpha-1.0)*delta)& (x<alpha*delta) )*x/delta-alpha*(x>alpha*delta)\n",
    "        hess = ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )/delta \n",
    "        return grad,hess\n",
    "\n",
    "  \n",
    "    @staticmethod\n",
    "    def quantile_score(y_true, y_pred, alpha):\n",
    "        score = XGBQuantile.quantile_cost(x=y_true-y_pred,alpha=alpha)\n",
    "        score = np.sum(score)\n",
    "        return score\n",
    "  \n",
    "    @staticmethod\n",
    "    def quantile_cost(x, alpha):\n",
    "        return (alpha-1.0)*x*(x<0)+alpha*x*(x>=0)\n",
    "  \n",
    "    @staticmethod\n",
    "    def get_split_gain(gradient,hessian,l=1):\n",
    "        split_gain = list()\n",
    "        for i in range(gradient.shape[0]):\n",
    "            split_gain.append(np.sum(gradient[:i])/(np.sum(hessian[:i])+l)+np.sum(gradient[i:])/(np.sum(hessian[i:])+l)-np.sum(gradient)/(np.sum(hessian)+l) )\n",
    "    \n",
    "        return np.array(split_gain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
